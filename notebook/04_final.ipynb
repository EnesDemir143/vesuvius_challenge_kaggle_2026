{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Vesuvius Challenge Surface Detection - Final Notebook\n",
                "\n",
                "This notebook contains all code needed for training and generating a Kaggle submission."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required packages (run this cell first on Kaggle)\n",
                "!pip install -q monai tifffile imagecodecs scikit-learn"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ===== CONFIGURE THESE PATHS FOR KAGGLE =====\n",
                "DATA_DIR = '/kaggle/input/vesuvius-challenge-surface-detection'  # Change for Kaggle\n",
                "OUTPUT_DIR = '/kaggle/working'  # Change for Kaggle\n",
                "\n",
                "# For local testing:\n",
                "# DATA_DIR = '../dataset/raw'\n",
                "# OUTPUT_DIR = '.'\n",
                "\n",
                "TRAIN_CSV = f'{DATA_DIR}/train.csv'\n",
                "TEST_CSV = f'{DATA_DIR}/test.csv'\n",
                "TRAIN_IMAGES = f'{DATA_DIR}/train_images'\n",
                "TRAIN_LABELS = f'{DATA_DIR}/train_labels'\n",
                "TEST_IMAGES = f'{DATA_DIR}/test_images'\n",
                "\n",
                "# Hyperparameters\n",
                "MODEL_NAME = 'segresnet'\n",
                "BATCH_SIZE = 1\n",
                "EPOCHS = 50\n",
                "LEARNING_RATE = 1e-4\n",
                "VAL_RATIO = 0.2\n",
                "SEED = 42\n",
                "TARGET_SIZE = 128\n",
                "NUM_WORKERS = 0\n",
                "IGNORE_LABEL = 2  # Unlabeled pixels"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import random\n",
                "from pathlib import Path\n",
                "from typing import Optional, Tuple, List, Dict, Union, Callable\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import tifffile\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from torch.cuda.amp import GradScaler, autocast\n",
                "from scipy import ndimage\n",
                "\n",
                "# Set seeds\n",
                "def set_seed(seed):\n",
                "    random.seed(seed)\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    if torch.cuda.is_available():\n",
                "        torch.cuda.manual_seed_all(seed)\n",
                "\n",
                "set_seed(SEED)\n",
                "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f'Device: {DEVICE}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Exploration (EDA)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load CSVs\n",
                "train_df = pd.read_csv(TRAIN_CSV)\n",
                "train_df['id'] = train_df['id'].astype(str)\n",
                "test_df = pd.read_csv(TEST_CSV)\n",
                "test_df['id'] = test_df['id'].astype(str)\n",
                "\n",
                "print(f'Train samples: {len(train_df)}')\n",
                "print(f'Test samples: {len(test_df)}')\n",
                "print(f'\\nTrain columns: {list(train_df.columns)}')\n",
                "print(f'\\nScroll ID distribution:')\n",
                "print(train_df['scroll_id'].value_counts().sort_index())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check for missing files\n",
                "train_images_dir = Path(TRAIN_IMAGES)\n",
                "train_labels_dir = Path(TRAIN_LABELS)\n",
                "\n",
                "valid_ids = []\n",
                "for vol_id in train_df['id']:\n",
                "    img_path = train_images_dir / f'{vol_id}.tif'\n",
                "    lbl_path = train_labels_dir / f'{vol_id}.tif'\n",
                "    if img_path.exists() and lbl_path.exists():\n",
                "        valid_ids.append(vol_id)\n",
                "\n",
                "print(f'Valid samples (with both image and label): {len(valid_ids)}')\n",
                "print(f'Missing: {len(train_df) - len(valid_ids)}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Data Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize a sample volume\n",
                "if len(valid_ids) > 0:\n",
                "    sample_id = valid_ids[0]\n",
                "    img = tifffile.imread(train_images_dir / f'{sample_id}.tif')\n",
                "    lbl = tifffile.imread(train_labels_dir / f'{sample_id}.tif')\n",
                "    \n",
                "    print(f'Sample ID: {sample_id}')\n",
                "    print(f'Image shape: {img.shape}, dtype: {img.dtype}')\n",
                "    print(f'Label shape: {lbl.shape}, unique values: {np.unique(lbl)}')\n",
                "    \n",
                "    # Show middle slices\n",
                "    mid_z = img.shape[0] // 2\n",
                "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
                "    axes[0].imshow(img[mid_z], cmap='gray'); axes[0].set_title('Image (Z-slice)')\n",
                "    axes[1].imshow(lbl[mid_z], cmap='tab10', vmin=0, vmax=2); axes[1].set_title('Label (Z-slice)')\n",
                "    axes[2].imshow(img[mid_z] * 0.5 + lbl[mid_z] * 50, cmap='gray'); axes[2].set_title('Overlay')\n",
                "    plt.tight_layout(); plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Transforms & Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CenterCropOrPad:\n",
                "    def __init__(self, target_size: int = 128):\n",
                "        self.target_size = (target_size, target_size, target_size)\n",
                "    \n",
                "    def __call__(self, image, label=None):\n",
                "        for dim in range(3):\n",
                "            current = image.shape[dim]\n",
                "            target = self.target_size[dim]\n",
                "            if current > target:\n",
                "                start = (current - target) // 2\n",
                "                slices = [slice(None)] * 3\n",
                "                slices[dim] = slice(start, start + target)\n",
                "                image = image[tuple(slices)]\n",
                "                if label is not None:\n",
                "                    label = label[tuple(slices)]\n",
                "            elif current < target:\n",
                "                pad_before = (target - current) // 2\n",
                "                pad_after = target - current - pad_before\n",
                "                pad_width = [(0, 0)] * 3\n",
                "                pad_width[dim] = (pad_before, pad_after)\n",
                "                image = np.pad(image, pad_width, mode='constant', constant_values=0)\n",
                "                if label is not None:\n",
                "                    label = np.pad(label, pad_width, mode='constant', constant_values=2)\n",
                "        return (image, label) if label is not None else image\n",
                "\n",
                "class Normalize:\n",
                "    def __init__(self, mean=127.5, std=127.5):\n",
                "        self.mean, self.std = mean, std\n",
                "    def __call__(self, image, label=None):\n",
                "        image = (image.astype(np.float32) - self.mean) / self.std\n",
                "        return (image, label) if label is not None else image\n",
                "\n",
                "class ZJitter:\n",
                "    def __init__(self, jitter_range=5):\n",
                "        self.jitter_range = jitter_range\n",
                "    def __call__(self, image, label=None):\n",
                "        shift = np.random.randint(-self.jitter_range, self.jitter_range + 1)\n",
                "        if shift == 0:\n",
                "            return (image, label) if label is not None else image\n",
                "        image = np.roll(image, shift, axis=0)\n",
                "        if shift > 0: image[:shift] = 0\n",
                "        else: image[shift:] = 0\n",
                "        if label is not None:\n",
                "            label = np.roll(label, shift, axis=0)\n",
                "            if shift > 0: label[:shift] = 2\n",
                "            else: label[shift:] = 2\n",
                "            return image, label\n",
                "        return image\n",
                "\n",
                "class BasicAugs:\n",
                "    def __call__(self, image, label=None):\n",
                "        if np.random.random() < 0.5:  # H flip\n",
                "            image = np.flip(image, axis=2).copy()\n",
                "            if label is not None: label = np.flip(label, axis=2).copy()\n",
                "        if np.random.random() < 0.5:  # V flip\n",
                "            image = np.flip(image, axis=1).copy()\n",
                "            if label is not None: label = np.flip(label, axis=1).copy()\n",
                "        if np.random.random() < 0.5:  # Rot90\n",
                "            k = np.random.randint(1, 4)\n",
                "            image = np.rot90(image, k=k, axes=(1, 2)).copy()\n",
                "            if label is not None: label = np.rot90(label, k=k, axes=(1, 2)).copy()\n",
                "        return (image, label) if label is not None else image"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class VesuviusDataset(Dataset):\n",
                "    def __init__(self, vol_ids, images_dir, labels_dir=None, transforms=None, is_train=True):\n",
                "        self.vol_ids = vol_ids\n",
                "        self.images_dir = Path(images_dir)\n",
                "        self.labels_dir = Path(labels_dir) if labels_dir else None\n",
                "        self.transforms = transforms or []\n",
                "        self.is_train = is_train\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.vol_ids)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        vol_id = self.vol_ids[idx]\n",
                "        image = tifffile.imread(self.images_dir / f'{vol_id}.tif')\n",
                "        \n",
                "        label = None\n",
                "        if self.labels_dir:\n",
                "            lbl_path = self.labels_dir / f'{vol_id}.tif'\n",
                "            if lbl_path.exists():\n",
                "                label = tifffile.imread(lbl_path)\n",
                "        \n",
                "        for t in self.transforms:\n",
                "            if label is not None:\n",
                "                image, label = t(image, label)\n",
                "            else:\n",
                "                result = t(image, None)\n",
                "                image = result[0] if isinstance(result, tuple) else result\n",
                "        \n",
                "        image = torch.from_numpy(image).float().unsqueeze(0)  # [1, D, H, W]\n",
                "        if label is not None:\n",
                "            label = torch.from_numpy(label.astype(np.int64))\n",
                "        else:\n",
                "            label = torch.zeros(image.shape[1:], dtype=torch.long)\n",
                "        \n",
                "        return {'image': image, 'label': label, 'id': vol_id}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create train/val split\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "train_ids, val_ids = train_test_split(valid_ids, test_size=VAL_RATIO, random_state=SEED)\n",
                "print(f'Train: {len(train_ids)}, Val: {len(val_ids)}')\n",
                "\n",
                "# Transforms\n",
                "train_transforms = [CenterCropOrPad(TARGET_SIZE), ZJitter(5), BasicAugs(), Normalize()]\n",
                "val_transforms = [CenterCropOrPad(TARGET_SIZE), Normalize()]\n",
                "\n",
                "# Datasets\n",
                "train_ds = VesuviusDataset(train_ids, TRAIN_IMAGES, TRAIN_LABELS, train_transforms, is_train=True)\n",
                "val_ds = VesuviusDataset(val_ids, TRAIN_IMAGES, TRAIN_LABELS, val_transforms, is_train=False)\n",
                "\n",
                "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
                "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
                "\n",
                "print(f'Batches - Train: {len(train_loader)}, Val: {len(val_loader)}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Model & Metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_model(name='segresnet', in_channels=1, out_channels=2):\n",
                "    if name == 'segresnet':\n",
                "        from monai.networks.nets import SegResNet\n",
                "        return SegResNet(spatial_dims=3, in_channels=in_channels, out_channels=out_channels,\n",
                "                         init_filters=32, blocks_down=(1,2,2,4), blocks_up=(1,1,1))\n",
                "    elif name == 'unet':\n",
                "        from monai.networks.nets import UNet\n",
                "        return UNet(spatial_dims=3, in_channels=in_channels, out_channels=out_channels,\n",
                "                    channels=(32,64,128,256,512), strides=(2,2,2,2), num_res_units=2)\n",
                "    else:\n",
                "        raise ValueError(f'Unknown model: {name}')\n",
                "\n",
                "model = get_model(MODEL_NAME).to(DEVICE)\n",
                "print(f'Model: {MODEL_NAME}, Parameters: {sum(p.numel() for p in model.parameters()):,}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Metrics\n",
                "def dice_coefficient(pred, gt):\n",
                "    intersection = np.sum(pred & gt)\n",
                "    return 2 * intersection / (np.sum(pred) + np.sum(gt) + 1e-8)\n",
                "\n",
                "def surface_dice(pred, gt, tau=2.0):\n",
                "    from scipy.ndimage import distance_transform_edt, binary_erosion\n",
                "    if pred.sum() == 0 and gt.sum() == 0: return 1.0\n",
                "    if pred.sum() == 0 or gt.sum() == 0: return 0.0\n",
                "    pred_surface = pred ^ binary_erosion(pred)\n",
                "    gt_surface = gt ^ binary_erosion(gt)\n",
                "    dist_pred = distance_transform_edt(~gt_surface)\n",
                "    dist_gt = distance_transform_edt(~pred_surface)\n",
                "    pred_close = pred_surface & (dist_pred <= tau)\n",
                "    gt_close = gt_surface & (dist_gt <= tau)\n",
                "    return (pred_close.sum() + gt_close.sum()) / (pred_surface.sum() + gt_surface.sum() + 1e-8)\n",
                "\n",
                "def compute_metrics(pred, gt, ignore_label=2):\n",
                "    # Mask out ignored pixels\n",
                "    mask = gt != ignore_label\n",
                "    pred_masked = pred[mask]\n",
                "    gt_masked = gt[mask]\n",
                "    pred_bin = (pred_masked == 1).astype(np.uint8)\n",
                "    gt_bin = (gt_masked == 1).astype(np.uint8)\n",
                "    return {'dice': dice_coefficient(pred_bin, gt_bin)}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Custom loss that handles ignore_label\n",
                "class MaskedDiceCELoss(nn.Module):\n",
                "    def __init__(self, ignore_label=2):\n",
                "        super().__init__()\n",
                "        self.ignore_label = ignore_label\n",
                "        self.ce = nn.CrossEntropyLoss(ignore_index=ignore_label)\n",
                "    \n",
                "    def dice_loss(self, pred, target):\n",
                "        # pred: [B, C, D, H, W] softmax outputs\n",
                "        # target: [B, D, H, W] class indices\n",
                "        mask = target != self.ignore_label\n",
                "        pred_soft = torch.softmax(pred, dim=1)\n",
                "        \n",
                "        # Only compute dice for foreground class (class 1)\n",
                "        pred_fg = pred_soft[:, 1]  # [B, D, H, W]\n",
                "        target_fg = (target == 1).float()\n",
                "        \n",
                "        # Apply mask\n",
                "        pred_fg = pred_fg * mask\n",
                "        target_fg = target_fg * mask\n",
                "        \n",
                "        intersection = (pred_fg * target_fg).sum()\n",
                "        union = pred_fg.sum() + target_fg.sum()\n",
                "        dice = (2 * intersection + 1e-5) / (union + 1e-5)\n",
                "        return 1 - dice\n",
                "    \n",
                "    def forward(self, pred, target):\n",
                "        ce_loss = self.ce(pred, target)\n",
                "        dice_loss = self.dice_loss(pred, target)\n",
                "        return ce_loss + dice_loss\n",
                "\n",
                "criterion = MaskedDiceCELoss(ignore_label=IGNORE_LABEL)\n",
                "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
                "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-7)\n",
                "scaler = GradScaler()\n",
                "\n",
                "best_metric = 0.0\n",
                "history = {'train_loss': [], 'val_loss': [], 'val_dice': []}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for epoch in range(1, EPOCHS + 1):\n",
                "    # Train\n",
                "    model.train()\n",
                "    train_loss = 0.0\n",
                "    for batch in tqdm(train_loader, desc=f'Epoch {epoch} [Train]', leave=False):\n",
                "        images = batch['image'].to(DEVICE)\n",
                "        labels = batch['label'].to(DEVICE)  # [B, D, H, W] with values 0, 1, 2\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        with autocast():\n",
                "            outputs = model(images)  # [B, 2, D, H, W]\n",
                "            loss = criterion(outputs, labels)\n",
                "        scaler.scale(loss).backward()\n",
                "        scaler.step(optimizer)\n",
                "        scaler.update()\n",
                "        train_loss += loss.item()\n",
                "    \n",
                "    train_loss /= len(train_loader)\n",
                "    history['train_loss'].append(train_loss)\n",
                "    \n",
                "    # Validate\n",
                "    model.eval()\n",
                "    val_loss = 0.0\n",
                "    all_dice = []\n",
                "    with torch.no_grad():\n",
                "        for batch in tqdm(val_loader, desc=f'Epoch {epoch} [Val]', leave=False):\n",
                "            images = batch['image'].to(DEVICE)\n",
                "            labels = batch['label'].to(DEVICE)\n",
                "            \n",
                "            with autocast():\n",
                "                outputs = model(images)\n",
                "                loss = criterion(outputs, labels)\n",
                "            val_loss += loss.item()\n",
                "            \n",
                "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
                "            gts = batch['label'].cpu().numpy()\n",
                "            for p, g in zip(preds, gts):\n",
                "                m = compute_metrics(p, g, ignore_label=IGNORE_LABEL)\n",
                "                all_dice.append(m['dice'])\n",
                "    \n",
                "    val_loss /= len(val_loader)\n",
                "    val_dice = np.mean(all_dice)\n",
                "    history['val_loss'].append(val_loss)\n",
                "    history['val_dice'].append(val_dice)\n",
                "    \n",
                "    scheduler.step()\n",
                "    \n",
                "    # Save best\n",
                "    if val_dice > best_metric:\n",
                "        best_metric = val_dice\n",
                "        torch.save(model.state_dict(), f'{OUTPUT_DIR}/best_model.pth')\n",
                "        print(f'Epoch {epoch}: New best model saved! Dice={val_dice:.4f}')\n",
                "    \n",
                "    print(f'Epoch {epoch}/{EPOCHS} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Dice: {val_dice:.4f}')\n",
                "\n",
                "print(f'\\nTraining complete! Best Dice: {best_metric:.4f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot training curves\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "axes[0].plot(history['train_loss'], label='Train'); axes[0].plot(history['val_loss'], label='Val')\n",
                "axes[0].set_xlabel('Epoch'); axes[0].set_ylabel('Loss'); axes[0].legend(); axes[0].set_title('Loss')\n",
                "axes[1].plot(history['val_dice'])\n",
                "axes[1].set_xlabel('Epoch'); axes[1].set_ylabel('Dice'); axes[1].set_title('Validation Dice')\n",
                "plt.tight_layout(); plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Test Prediction & Submission"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best model\n",
                "model.load_state_dict(torch.load(f'{OUTPUT_DIR}/best_model.pth', map_location=DEVICE))\n",
                "model.eval()\n",
                "\n",
                "# Test dataset - IMPORTANT: Use val_transforms (no augmentation)\n",
                "test_ids = test_df['id'].tolist()\n",
                "test_ds = VesuviusDataset(test_ids, TEST_IMAGES, labels_dir=None, transforms=val_transforms, is_train=False)\n",
                "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=0)\n",
                "\n",
                "print(f'Test samples: {len(test_ds)}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate predictions and create submission\n",
                "submissions = []\n",
                "\n",
                "for batch in tqdm(test_loader, desc='Generating predictions'):\n",
                "    vol_id = batch['id'][0]\n",
                "    image = batch['image'].to(DEVICE)\n",
                "    \n",
                "    with torch.no_grad(), autocast():\n",
                "        output = model(image)\n",
                "        pred = output.argmax(dim=1).squeeze().cpu().numpy()\n",
                "    \n",
                "    # RLE encode the prediction\n",
                "    pred_flat = pred.flatten()\n",
                "    pred_flat = np.concatenate([[0], pred_flat, [0]])\n",
                "    runs = np.where(pred_flat[1:] != pred_flat[:-1])[0] + 1\n",
                "    runs[1::2] -= runs[::2]\n",
                "    rle = ' '.join(str(x) for x in runs)\n",
                "    \n",
                "    submissions.append({'id': vol_id, 'rle': rle})\n",
                "\n",
                "# Save submission\n",
                "submission_df = pd.DataFrame(submissions)\n",
                "submission_df.to_csv(f'{OUTPUT_DIR}/submission.csv', index=False)\n",
                "print(f'Submission saved to {OUTPUT_DIR}/submission.csv')\n",
                "print(submission_df.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('\\n=== NOTEBOOK COMPLETE ===')\n",
                "print(f'Best validation Dice: {best_metric:.4f}')\n",
                "print(f'Submission file: {OUTPUT_DIR}/submission.csv')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
